# EthioMed: AI-Enriched Medical Data Warehouse

**Author:** Maireg  
**Role:** Data Engineer at Kara Solutions  
**Status:** Final Submission (Completed Task 1â€“5)

---

## ğŸ“Œ Project Overview
EthioMed is a production-ready data engineering pipeline that transforms unstructured data from Ethiopian medical Telegram channels into a structured, AI-enriched analytical warehouse. 

By integrating **Computer Vision (YOLOv8)**, **dbt for dimensional modeling**, and **Dagster for orchestration**, the platform provides actionable insights into medical product trends, promotional strategies, and channel activity across Ethiopia.

---

## ğŸ—ï¸ Technical Architecture
The project follows a modern **ELT (Extract, Load, Transform)** architecture:

*   **Ingestion (Extract):** Telethon-based scrapers extract raw messages and images.
*   **Enrichment (AI/CV):** **YOLOv8** processes images to categorize content.
*   **Storage (Load):** Raw data (JSON) and YOLO results (CSV) are loaded into **PostgreSQL**.
*   **Transformation (Transform):** **dbt** models raw data into a cleaned **Star Schema** with quality tests.
*   **Serving (API):** **FastAPI** serves analytical endpoints for business reporting.
*   **Orchestration:** **Dagster** manages lineage, daily scheduling, and automated testing.

---

## ğŸ“‚ Project Structure
```text
Telegram-Medical-Pipeline/
â”œâ”€â”€ api/                        # FastAPI Application
â”œâ”€â”€ data/                       # Local Data Lake (GitIgnored)
â”œâ”€â”€ medical_warehouse/          # dbt Project
â”œâ”€â”€ scripts/                    # Maintenance & Loading Scripts
â”œâ”€â”€ src/                        # Data Acquisition & Enrichment
â”œâ”€â”€ pipeline.py                 # Dagster Orchestration & Scheduling
â”œâ”€â”€ docker-compose.yml          # PostgreSQL Orchestration
â””â”€â”€ requirements.txt            # Project Dependencies

âš™ï¸ Running the Pipeline

1. Automated Orchestration (Dagster)
The entire pipeline is orchestrated via Dagster.
code
Bash
dagster dev -f pipeline.py
Hardening: Includes an automated Daily Schedule and integrated dbt tests.

2. Serve the API
Expose the data warehouse insights:
code
Bash
uvicorn api.main:app --reload
Interactive Documentation: http://127.0.0.1:8000/docs

ğŸ›¡ï¸ Production Hardening (Final Deliverables)

Automated Scheduling: Configured Dagster schedules for daily data refreshes.
Integrated Testing: Automated dbt test execution within the pipeline.
Analytical API: 4 endpoints providing real-time warehouse insights.
Author Maireg
January 20, 2026